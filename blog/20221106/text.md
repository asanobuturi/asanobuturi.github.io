ツイッターで、最近新しく公開された音声合成AI「MoeGoe」が話題になっていたので、試してみました。

## MoeGoeとは

まずはこちらをご覧ください。

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">なにやら中国の方が作られた音声合成AI「MoeGoe」の2891人の日本アニメキャラの音声モデルが公開されてしまった！！Hugging Faceでデモが試せる！早速まどマギの５人に喋ってもらった！！うわうわうわ！ヤバいよヤバい本当にヤバいよコレはヤバい！！　　<a href="https://t.co/wzHJdwEvr7">https://t.co/wzHJdwEvr7</a> <a href="https://t.co/EFgUId9qpd">pic.twitter.com/EFgUId9qpd</a></p>&mdash; うみゆき@AI研究 (@umiyuki_ai) <a href="https://twitter.com/umiyuki_ai/status/1588868531416109057?ref_src=twsrc%5Etfw">November 5, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

MoeGoeは、最新のアニメ声合成AIです。名称は日本語の「萌え声」が由来だと思われますが、開発者は中国人の方のようです。GitHub及びHuggingFaceでソースコードや学習済みモデルなどが配布されており、誰でも試すことができます。学習済みモデルに関しては、商用利用は固く禁止されています。

技術的には、昨年韓国で開発された音声合成技術の「VITS」を応用したものになっているようです。VITSは今年初めごろに日本でも話題を呼び、複数の日本語による実装レポートもWEB上で発表されました。(Qiita「[【機械学習】VITSでアニメ声へ変換できるボイスチェンジャー&読み上げ器を作った話](https://qiita.com/zassou65535/items/00d7d5562711b89689a8)」など)

VITSの仕組みについては一応英語の論文があるので、そちらをご覧ください。15ページ程度ですが私には読めません。([https://arxiv.org/abs/2106.06103](https://arxiv.org/abs/2106.06103))

また、学習に際しては、アニメのセリフを中心に多くの音声をデータベース化し配信しているウェブサイト「VoiStock」などから収集したデータを一部のモデルで使用しているとのことです。NovelAIがStableDiffusionベースのアニメイラスト生成AIをリリースした際、学習に使用したデータがイラストの無断転載サイトから入手したものであったことがネット上で非難の対象になりましたが、このサイトについても著作権周りのことは少し気がかりです。

作者のCjangCjenghさんがビリビリ動画に公開している紹介動画も併せてご覧ください。([https://www.bilibili.com/video/BV1P8411Y7v5/](https://www.bilibili.com/video/BV1P8411Y7v5/))

## MoeGoeを試す方法3つ

MoeGoeは現在、GitHubで公開されているプログラムのほか、HuggingFace上のオンラインデモページ、Microsoft Azure上に構築された合成済み音声を返すAPIとそれを利用したAndroid向けアプリなどが主にリリースされています。

とりあえず試してみるだけであれば、すぐにブラウザから使用することができるHuggingFace版を試すのが良いでしょう。Androidユーザーの場合はアプリ版も有用です。以下にリンクを記載しています。

- [HuggingFaceのデモページ(ブラウザ版、PC・スマホ等対応)]()
- [Android版アプリ(Google Play)](https://play.google.com/store/apps/details?id=top.fumiama.moegoe)

この記事では、せっかくなのでGitHubで公開されているものを実際に手元のパソコンで実行することを試みます。(といってもめちゃくちゃ簡単です)

## MoeGoeをローカル環境(自分のパソコン)で実行しよう

**※下記のソフトウェアを使用して発生したいかなる問題についても、私達は責任を負いかねます。**

現在、MoeGoeのプログラムはWindows用のものしか配布されていないので、実行にはWindowsパソコンが必要です。実装自体はPythonですので、技術的にはMac、Linux等でも実行出来ると思われます(GUIアプリを除く)。

また、7-Zip形式の圧縮ファイルを解凍できるソフトウェアが何かしら必要です。7-Zipをインストールしておけば問題ないでしょう。

Windowsパソコンさえ用意できれば、実行ファイルは全て完全にexeファイルにまとめられているので、ソースコードのビルドなどに怖気づく必要は全くありません(私はexeファイルがあるのに気づかず、プログラムを地道にビルドしようとしてVisualStudioの依存関係不足で時間を溶かされました)。

以下、手順を示します。

### MoeGoeの実行ファイルをダウンロード

まずは[MoeGoeのGitHubレポジトリにあるReleasesページ](https://github.com/CjangCjengh/MoeGoe/releases)をブラウザで開き、最新のMoeGoeの実行ファイル(exeファイル)をダウンロードします。この記事の執筆時点で最新版はVer.3.0.0でした。「MoeGoe.7z」と書かれているファイルをダウンロードし解凍してください。

![](1.jpg)

**MoeGoeのReleasesページ：**[https://github.com/CjangCjengh/MoeGoe/releases](https://github.com/CjangCjengh/MoeGoe/releases)

### 便利なMoeGoeのGUIアプリをダウンロード

このファイルだけでも実行することは可能ですが、コマンドライン上での操作となり不便ですので、GUIアプリも続けてダウンロードします。[MoeGoe GUIのReleasesページ](https://github.com/CjangCjengh/MoeGoe_GUI/releases)から、最新の「MoeGoe_GUI.exe」をダウンロードします。先ほど解凍したMoeGoeのフォルダーの中に入れておくのが便利ではないでしょうか。

![](2.jpg)

**MoeGoe GUIのReleasesページ：**[https://github.com/CjangCjengh/MoeGoe_GUI/releases](https://github.com/CjangCjengh/MoeGoe_GUI/releases)

### 学習済みモデルのダウンロード

最後に、各キャラクターのボイスを学習した学習済みモデルをダウンロードします。[GitHubページ](https://github.com/CjangCjengh/TTSModels)から好きな物を選んで、それぞれ「Config File」と「Model」を両方ダウンロードしてください。私はMoeGoeのフォルダー内に「models」というフォルダーを作成し、その中に配置しましたが、ファイルがどこに合ってもあとでその場所を適宜指定するだけなので問題ありません。

複数のモデルをダウンロードする場合は、以下のように適宜分かりやすいように名前を変更しておいた方が無難です。

モデルごとに対応している言語が異なっているので、ダウンロードリンクの上に書かれている対応言語を確認してください。中には日本語非対応のモデルもいくつかあります。

「ゼロの使い魔」や「ToLoveるダークネス」など絶妙に古いアニメのモデルが多いです。開発者の推しなのか、ノベルゲームメーカー「ゆずソフト」のキャラクターのモデルがなかなか充実しています。

また、下部にあるVoistockモデルは、先述のアニメ音声収集サイトから大量のデータベース化された音声を収集して学習した大型モデルで、3000人弱のキャラ(海外版声優と日本語版声優・同じ声優の演じる別キャラなどの重複はあるとみられる)の音声を学習しているモデルです。これが事実上の標準モデルでしょうか。日本語以外に英語、韓国語、中国語にも対応しています。

**MoeGoeの学習済みモデルの配布ページ：**[https://github.com/CjangCjengh/TTSModels](https://github.com/CjangCjengh/TTSModels)

### 実際に動かす

全ての必要ファイルのダウンロードが終わったところで、実際に音声合成を試してみましょう。

MoeGoe_GUI.exeを実行します。

![](3.JPG)

このような画面が起動するので、それぞれのメニューについて、上から順に、以下のファイルを指定します。

- 「打开文件」：「ファイルを開く」の意。このボタンをクリックして、先ほど解凍したフォルダーの中にある「MoeGoe.exe」のファイルを指定する。
- 「VITS」「HuBERT-VITS」「W2V2-VITS」のメニュー：AIモデルの種類を指定する。MoeGoeが現在公開している学習済みモデルのほとんどがVITSなので、基本的にはVITSを指定しておけば問題ない。モデルをダウンロードしたページに、そのモデルがVITSなのか、HuBERT-VITSなのかといったことが書いてあるので確認する。
- 「打开模型」：「モデルを開く」の意。このボタンをクリックして、使いたいモデルの.pthファイルを指定する。
- 「打开配置」：「設定を開く」の意。このボタンをクリックして、先ほど指定したモデルに対応するconfig.jsonファイルを指定する。

モデルを設定出来たら、「文本」の画面に喋らせたい文章の内容を入力し、「说话人」に表示されるリストから、喋らせたいキャラクターを選択します。

最後に、保存ボタンをクリックし、保存先を指定すると、合成された音声が保存されます。「重新合成」は上書き保存、「删除」は削除、「播放」は保存した音声の再生、「停止」は再生中の音声の停止です。

また、一部の複数言語に対応したモデルを使用する際には、``[JA]こんにちは[JA]``や``[ZH]你好[ZH]``のように、中括弧で言語を示す必要があります。日本語はJA、中国語はZH、韓国語はKO、英語はENです。

![](4.JPG)

設定はこのようになります。MoeGoe_GUIのアプリを日本語化してみたのですが、あとでMoeGoe_GUIのソースコードのライセンスが不明なことに気づき、公開はしていません。MoeGoe本体はMITライセンスだったので、いつかMoeGoe_GUIのライセンスが更新されたら、日本語化したものをGitHub上で公開するかもしれません。(ちなみに、「文章を消去」はおそらく誤訳で、発音・アクセント・イントネーションの手動設定？が正しい)

## 合成した音声は載せません

今の段階では権利関係があまりに不透明すぎると思ったため。

代わりに、TwitterやYouTube、ビリビリ動画にあるおすすめの動画をいくつかご紹介します。

- [包含2890名动画角色的VITS语音合成模型(2980人のアニメキャラの声を搭載したVITS音声合成モデル) - ビリビリ動画](https://www.bilibili.com/video/BV1P8411Y7v5/)：冒頭で紹介した、作者のCjangCjenghさんの動画です。58秒ごろから、合成音声のサンプルが流れます。
- [綾地寧々の声を作ってみた - YouTube](https://youtu.be/k37NYU41O_M)：同じく作者のCjangCjenghさんがYouTubeに公開している動画です。ビリビリ動画よりも視聴ハードルが低いので、YouTubeじゃないと見れないという場合にはこちらがおすすめです。ただし、少し古いバージョンの合成システムを使用しているものと思われます。
- [日本語Ｎ１聴解問題 - YouTube](https://youtu.be/Vfx81Noux1w)：こちらも作者のCjangCjenghさんがYouTubeに公開している動画です。日本語検定1級のリスニング問題を萌え声で再現しています。
- [MoeGoeのボイチェン(halfmony氏) - Twitter](https://twitter.com/halfmony/status/1589098771639865344) ：MoeGoe特有のイントネーションの弱さは、適切に発音された音声にボイスチェンジャーをかけることで改善できそう。

## 感想

音声合成のクオリティは総じて高く、VITSの技術を応用した製品の実用化が待たれます。

ただし、単純な音声の精度に関してのみ言えば、企業の資本のもとで、音声合成のために厳密に管理された録音環境で得たデータをもとに開発された音声合成ソフトウェアの方が、明らかに高性能な印象を受けました。最近では、AHS社のVOICEPEAKはかなりレベルの高い音声を出力しています。

MoeGoe(VITS)の真価は、音声合成ソフトとしてリリースされていない、一般のアニメのキャラクターの声から学習したモデルを利用できることです。ですが、それにはここ最近議論を巻き起こしているStable Diffusion以上に、権利問題が付きまとう事でしょう。必然的に、個別的な声優さんやキャラクターに一対一で対応する声を生成することになるからです。Stable Diffusionの日本国内向けの紹介記事をおそらく最初期に執筆([記事リンク](https://note.com/fladdict/n/n13c1413c40de))された、note株式会社の深津貴之さんも、これについて憂慮の念を示しています。

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">これはやりすぎ…というか、個別のクリエイターの狙い撃ちクローンは良くない。こういうのが増えると、色々と拗れてしまう <a href="https://t.co/p1ycQvrNZf">https://t.co/p1ycQvrNZf</a></p>&mdash; 深津 貴之 / THE GUILD / note.com (@fladdict) <a href="https://twitter.com/fladdict/status/1588882955363311617?ref_src=twsrc%5Etfw">November 5, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

MoeGoeには、日本語の音声しか存在しないはずのキャラクターに対して、声優さんの声を変えないまま中国語、韓国語、英語などの音声を出力できるモデルが存在します。このような技術が発展すれば、映像コンテンツの翻訳の際に、吹き替え版に別の声優さんを起用することなく、日本のアニメをそのままの声で中国語に拭き替えたり、ハリウッドの映画を現地の俳優さんの声のまま日本語に吹き替えたりすることが出来るようになるかもしれません。非常に期待のできる技術なのではないでしょうか。

本当に人間の仕事を奪うような、クリエイティビティあふれる生成AIが登場するのも時間の問題なのかもしれません。